{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model = AutoModelForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\", num_labels=10, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_image_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through the subdirectories (classes)\n",
    "    for class_dir in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_dir)\n",
    "\n",
    "        # Iterate through the images in each class\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            curr_image = Image.open(image_path)\n",
    "            images.append(curr_image)\n",
    "            labels.append(class_dir)\n",
    "    labels = [int(label)-1 for label in labels]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "image_paths, labels = load_image_data('./dataset/CSE164_2023/Train_set/')\n",
    "data = {\"image\": image_paths, \"label\": labels}\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised training using the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./swin_t_output/final_test/\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetune_model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=train_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test accuracy using the model trained only using labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "test_dir = \"./dataset/CSE164_2023/test_set/Test_set/\"\n",
    "image_labels = []\n",
    "count = 0\n",
    "for file in os.listdir(test_dir):\n",
    "    file_path = os.path.join(test_dir, file)\n",
    "    image = Image.open(file_path)\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "    inputs['pixel_values'] = inputs['pixel_values'].cuda()\n",
    "    #inputs = image_processor(image, return_tensors=\"tf\")\n",
    "    logits = finetune_model(**inputs).logits\n",
    "    predicted_class_id = int(torch.argmax(logits, axis=-1)[0])\n",
    "    image_labels.append([file, predicted_class_id])\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file_path = \"submission.csv\"\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(file_path, mode=\"w\", newline=\"\") as file:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"Image_id\", \"label\"])\n",
    "\n",
    "    # Write the data rows\n",
    "    writer.writerows(image_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling and semi-supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data_dir = \"./dataset/CSE164_2023/unlabeled_data/Unlabeled_data/\"\n",
    "def load_test_set(unlabled_data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for image_file in unlabled_data:\n",
    "        image_path = os.path.join(data_dir, image_file)\n",
    "        img = Image.open(image_path)\n",
    "        inputs = image_processor(img, return_tensors=\"pt\")\n",
    "        inputs['pixel_values'] = inputs['pixel_values'].cuda()\n",
    "        \n",
    "        logits = finetune_model(**inputs).logits\n",
    "        predicted_class_id = int(torch.argmax(logits, axis=-1)[0])\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(predicted_class_id)\n",
    "        print(count)\n",
    "        count += 1\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(curr_data):\n",
    "    unlabeles_images, pseudo_labels = load_test_set(curr_data)\n",
    "    unlabelled_data = {\"image\": unlabeles_images, \"label\": pseudo_labels}\n",
    "    unlabeled_dataset = Dataset.from_dict(unlabelled_data)\n",
    "    unlabeled_train_ds = unlabeled_dataset.with_transform(transforms)\n",
    "\n",
    "    return unlabeled_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = os.listdir(data_dir)\n",
    "number_batches = len(unlabeled_data)//2000\n",
    "\n",
    "for i in range(number_batches):\n",
    "    curr_data = unlabeled_data[i*2000:(i+1)*2000]\n",
    "    unlabeled_train_ds = prepare_dataset(curr_data)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./swin_t_output/final_finetuning/\",\n",
    "        remove_unused_columns=False,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer_uds = Trainer(\n",
    "        model=finetune_model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=unlabeled_train_ds,\n",
    "        eval_dataset=train_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer_uds.train()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_dir = \"./dataset/CSE164_2023/test_set/Test_set/\"\n",
    "image_labels = []\n",
    "count = 0\n",
    "for file in os.listdir(test_dir):\n",
    "    file_path = os.path.join(test_dir, file)\n",
    "    image = Image.open(file_path)\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "    inputs['pixel_values'] = inputs['pixel_values'].cuda()\n",
    "    #inputs = image_processor(image, return_tensors=\"tf\")\n",
    "    logits = finetune_model(**inputs).logits\n",
    "    predicted_class_id = int(torch.argmax(logits, axis=-1)[0])\n",
    "    image_labels.append([file, predicted_class_id])\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file_path = \"submission.csv\"\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(file_path, mode=\"w\", newline=\"\") as file:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"Image_id\", \"label\"])\n",
    "\n",
    "    # Write the data rows\n",
    "    writer.writerows(image_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce result using trained (saved) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "saved_model = AutoModelForImageClassification.from_pretrained(\"./swin_t_output/final_finetuning/checkpoint-30/\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "test_dir = \"./dataset/CSE164_2023/test_set/Test_set/\"\n",
    "image_labels = []\n",
    "count = 0\n",
    "for file in os.listdir(test_dir):\n",
    "    file_path = os.path.join(test_dir, file)\n",
    "    image = Image.open(file_path)\n",
    "    inputs = image_processor(image, return_tensors=\"pt\")\n",
    "    inputs['pixel_values'] = inputs['pixel_values'].cuda()\n",
    "    #inputs = image_processor(image, return_tensors=\"tf\")\n",
    "    logits = saved_model(**inputs).logits\n",
    "    predicted_class_id = int(torch.argmax(logits, axis=-1)[0])\n",
    "    image_labels.append([file, predicted_class_id])\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file_path = \"submission.csv\"\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(file_path, mode=\"w\", newline=\"\") as file:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"Image_id\", \"label\"])\n",
    "\n",
    "    # Write the data rows\n",
    "    writer.writerows(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse164",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
